---
title: "Diferencial Expression with Sleuth"
author: "Luiz Carlos Vieira"
date: "23/03/2022"
output: pdf_document
---

# Sleuth

Sleuth is a program for differential analysis of RNA-Seq data. It makes use of quantification uncertainty 
estimates obtained via kallisto for accurate differential analysis of isoforms or genes, allows testing in the
context of experiments with complex designs, and supports interactive exploratory data analysis via sleuth live.
The sleuth methods are described in:

H Pimentel, NL Bray, S Puente, P Melsted and Lior Pachter, Differential analysis of RNA-seq incorporating quantification uncertainty, Nature Methods (2017), advanced access.


## Instalation of leuth
```{r}
#BiocManager::install("pachterlab/sleuth")
```
I got an ERRO:

namespace:rhdf5' Execution halted ERROR: lazy loading failed for package 'sleuth'

removing 'C:/Users/31625/Documents/R/win-library/4.1/sleuth'


## Working around

* Run git clone https://github.com/pachterlab/sleuth

* Remove the last line in ./sleuth/NAMESPACE file which is the h5write.default that raises the error during installation - ignore the warning in the first line

* Then in R:
make sure to set work env in R env to the same local where git was cloned.
```{r}
# setwd("C:/Users/username/Downloads")
# devtools::install('./sleuth/')
```


## Loading libraries 
```{r include=FALSE}
library(sleuth)
library(dplyr)
library(ggplot2)
library(ggrepel)
library(lemon)
library(cowplot)
library(readxl)
```


## Get help
```{r}
#vignette('intro', package = 'sleuth')
#help(package = 'sleuth')
```


# Sleuth for estimation of differential expression of transcripts

The workflow for Sleuth is similar to the workflow followed for DESeq2, even though, the models for estimating differential expression are very different.

* Step 1: Creation of Sleuth object to provide metadata, estimated counts, and design formula for the analysis, 
in addition to a annotables database to switch between transcript IDs and associated gene names.

* Step 2: Fit the sleuth model

Estimation of size (normalization) factors using the median of ratios method (similar to DESeq2)

Normalization of estimated counts using size factors (est. counts / size factors - similar to DESeq2)

Filtering of low abundance transcripts (< 5 est counts in more than 47% of the samples)

Normalization of technical variation estimates

Estimation of biological variance and shrinkage estimates (With small sample sizes, we will make very bad 
estimates of transcript-wise dispersion unless we share information across transcripts. Sleuth regularizes 
the biological variance estimate with shrinkage, similar to DESeq2, except uses a different statistical method
(similar to Limma Voom).)

Parameter estimation and estimation of variance using the general linear model.

Identification of:

Coefficients: indicating overall expression strength
Beta values: estimates of fold changes

* Step 3: Test for significant differences between conditions


# Sleuth workflow

## Step 1: Create Sleuth object for analysis

Similar to DESeq2, we need to tell Sleuth where to find the metadata (specifying which sample groups the 
samples belong to, and any other metadata we want included in the analysis), estimated counts (output from kallisto) and the design formula. 

To create this Sleuth object, we need to perform the following steps:

Create a dataframe containing metadata and locations of the estimated counts files:

- a column named sample containing all of the sample names matching the names in the metadata file.
- a column named condition containing the groups of study like treatment and control.
- a column named path containing the path to the abundance estimate files output from kallisto.


## Creating a metadata dataframe

Create metadata associated with the kallisto files as in the DESeq2 using the data.frame().
```{r}
base_dir <- "kallisto/quant"

sample_id <- dir(file.path(base_dir))


# Sleuth requires a column entitled “sample” containing the sample names:
metadata <- data.frame(sample = sample_id,
                          condition = factor(c(rep("Con", 3),
                                               rep("RNAi", 3))))
```


## Creating a list of the paths to our transcript abundance files:

First, we create a simple vector containing the paths to the directories containing the transcript abundance 
estimates for each sample (folders containing the .quant files).
```{r}
# file.path() function gives the paths to each of the directories.
paths <- file.path(base_dir, sample_id)

paths
```


## Naming the vector of directory paths with the corresponding sample names
```{r}
# Name the directory paths for the abundance files with their corresponding sample IDs
names(paths) <- sample_id

paths
```


## Combining the metadata with the paths 

Combining the metadata with the paths to the transcript abundance files to use as input for the Sleuth analysis.

Sleuth requires a column entitled “path” containing the paths to the estimated counts files stored in our sf_dirs:
```{r}
# Adding a column named 'path'
metadata$path <- paths

metadata
```


## Defining condition levels

NOTE: Sleuth will automatically use the first level (alphabetically by default) in the factor variable being 
tested to compare all other conditions against (in the metadata, this is ‘AW’, but in other cases like: 
control vs treated, coltrol will be used as first level). 

If you want to use a different condition to be the base level, then you would need to use the relevel() function
to change the base level of the variable.

For example, if we wanted the base level of condition to be “W”, we could use the following code:
```{r}
metadata$condition <- relevel(metadata$condition, ref = "Con")
```


## Creating a variable containing the model design

With the metadata and location of the count estimates, we can input our design formula to determine the 
covariates and/or confounders that should be included in your experimental design model. 

Sleuth can be used to analyze multiple conditions from complex experimental designs. Within Sleuth, models are 
written similar to DESeq2.
```{r}
design <- ~ condition
```


# Step 2: Fit the sleuth model

Fit the transcript abundance data to the Sleuth model Using the sleuth_prep() function, the counts are normalized 
and filtered, then merged with the metadata. In addition, the bootstraps for each transcript are summarized. 

This function can take a bit of time, but there is an option (ncores) to split across multiple processors.
```{r}
# Create sleuth object for analysis 

so <- sleuth_prep(metadata, 
                  full_model = design, 
                  #target_mapping = t2g,
                  num_cores = 4L,
                  read_bootstrap_tpm = TRUE,
                  extra_bootstrap_summary = TRUE,
                  transform_fun_counts = function(x) log2(x + 0.5)
                  )
```
NOTE: By default the transformation of counts is natural log, which would make the output fold changes somewhat 
more difficult to interpret. By specifying the transform_fun_counts to be log2(x + 0.5) we are ensuring our 
output fold changes are log2.

offset = 0.5 is need to to prevent taking the log of 0.


## Fitting the sleuth model 

sleuth performs shrinkage of variance, parameter estimation and estimation of variance using the general linear model:
```{r}
so <- sleuth_fit(so)
```

## Check which models have been fit and which coefficients can be tested

Ensure the design model and coefficients are correct for your analysis. 

The level not shown is the base level.
```{r}
models(so)
```


## Step 3: Test significant differences between conditions using the Wald test

At this step in the workflow, we need to specify which level we want to compare against the base level 
(use the name given for the coefficients from models(so)):

# Wald test for differential expression of isoforms
```{r}
DE_RNAi <- sleuth_wt(so, which_beta = 'conditionRNAi')


# Get results
sleuth_results_RNAi <- sleuth_results(DE_RNAi, 
                                    test = 'conditionRNAi', 
                                    show_all = TRUE)
```
NOTE: The output represents the results from the differential expression testing with the following columns:

* target_id: the Ensembl transcript ID
* pval: the Wald test FDR adjusted pvalue using Benjamini-Hochberg
* qval: the p-value adjusted for multiple test correction
* b: beta value, which is the log2 fold changes between conditions (These are log2 b/c we specified log2 
transformation in the sleuth_prep() step. By default, these would have been natural log fold changes).
* se_b: standard error of the beta value
* mean_obs: the mean expression (log2) of the transcript across all samples
* var_obs: the biological variance of the expression
* tech_var: the technical variance of expression (derived from the bootstraps)
* sigma_sq: raw estimator of the variance once the technical variance has been removed
* smooth_sigma_sq: the smooth regression fit for the shrinkage estimation
* final_sigma_sq: max(sigma_sq, smooth_sigma_sq). this is the one used for covariance estimation of beta 
(in addition to tech_var)
* ens_gene: associated Ensembl gene ID
* ext_gene: associated gene symbol


## Salving results table
```{r}
#write.xlsx(sleuth_results_AW, file='results/sleuth_results_AW.xlsx', sheetName = "DE_AW", 
#  col.names = TRUE, row.names = FALSE, append = FALSE)
#
#write.xlsx(sleuth_results_Q, file='results/sleuth_results_Q.xlsx', sheetName = "DE_Q", 
#  col.names = TRUE, row.names = FALSE, append = FALSE)
```


## Acesse o Shiny dos resultados (precisa de tela gráfica):
```{r}
#sleuth_live(so)
```


# Results and visualization


Transcrits of interest: "XM_001120691.5", "XM_393605.7", "XM_624635.6", "lncov1"
```{r}
txI <- c("XM_001120691.5", "XM_624635.6", "lncov1", "XM_006569892.2") 
```


## 1. Get Differencial expressed transcripts results table
```{r}
sleuth_sig_RNAi <- dplyr::filter(sleuth_results_RNAi, pval <= 0.05)

head(sleuth_sig_RNAi)
```

## 1.2 Get bootstrap summary

The bootstrap outputs are stored in the .h5 files, they are generated by resampling the original data and
finding the expression for this new dataset. This is why we will get slightly different est_counts in the 
bootstraps, and the amount of variation gives you an indication of how reliable the initial point estimate is.

Getting the Maximum likelihood estimation est_counts or tpm from bootstraps from all samples. 
```{r}
head(as.data.frame(so$obs_norm), 10)
```

Getting the bootstraps summary of est_counts or tpm from each sample. 
```{r}
s1 <- as.data.frame(so$bs_quants$SRR7908186$est_counts)

dplyr::filter(s1, row.names(s1) == "lncov1")
```

Getting the bootstrap summary from all samples with the function get_bootstrap_summary()
```{r}
bt_summ <- get_bootstrap_summary(so, "lncov1", units = "est_counts")
bt_summ
```

# 2. Volcano plot

volcano plot, Plots of beta value (regression) versus log of significance p-values.

## Volcano plot Queen vs Worker
```{r, , fig.height=5, fig.width=9}
dt <- as.data.frame(sleuth_results_RNAi)
dt <- na.omit(dt)
dt$significant <- ifelse(dt$qval<0.05, "True", "False")
dt[which(abs(dt$b)<0.5),'significant'] <- "False"
dt <- dt[order(dt$pval),]


legen <- dt[dt$target_id %in% txI, ]
legen$target_id <- recode(legen$target_id, XM_001120691.5 = "LOC726407",
                          #XM_393605.7 = "Gapdh", 
                          XM_624635.6 = "Tudor-SN",
                          XM_006569892.2 = "Ef1α")

volcano = ggplot(dt, aes(b, -log10(qval))) + 
  geom_point(aes(col=significant)) +
  scale_color_manual(values=c("red", "gray"))


volcano + geom_label_repel(data= legen, aes(label= legen$target_id), size=4, fontface = "italic",
  box.padding = unit(2, "lines"), point.padding = unit(5, "points")) +
  labs(title= "Volcano plot of Diferencial Expressed Transcripts",
       subtitle = "Comparison of RNAi x Control",
       x= expression(paste("Log"[2], " fold change")), 
       y= expression(paste("q-value (-log"[10], ")")),
       color="Differentially Expressed") +
  theme_bw() + coord_cartesian(clip = "off")
ggsave(file="results/volcano_rnai_x_con.jpeg", height=5, width=9, dpi=300)
```



## 3. PCA
```{r, fig.height=5, fig.width=9}
#png("results/pca-transcritos.png",height = 8, width = 10, units = 'in',res=600)

plot_pca(so, pc_x = 1L, pc_y = 2L, use_filtered = TRUE,
  units = "est_counts", text_labels = F, color_by = "condition",
  point_size = 4) +
  theme_bw() + # remove default ggplot2 theme
  ggtitle(label = "Principal Component Analysis (PCA)", 
          subtitle = "Variance among worker, queenless-worker and queen")
```


## 4. Density
```{r, fig.height=5, fig.width=9}
plot_group_density(so, use_filtered = TRUE, units = "est_counts",
                   trans = "log", grouping = "condition", offset = 1)  
```


## 5. Boxplots

### Definitions of the values plotted in the boxplots:

* Minimum Score: The lowest score, excluding outliers (shown at the end of the left whisker).

* Lower Quartile: Twenty-five percent of scores fall below the lower quartile value (also known as the first 
quartile).

* Median: The median marks the mid-point of the data and is shown by the line that divides the box into two parts (sometimes known as the second quartile). Half the scores are greater than or equal to this value and half are 
less.

* Upper Quartile: Seventy-five percent of the scores fall below the upper quartile value (also known as the 
third quartile). Thus, 25% of data are above this value.

* Maximum Score: The highest score, excluding outliers (shown at the end of the right whisker).

* Whiskers: The upper and lower whiskers represent scores outside the middle 50% (i.e. the lower 25% of scores 
and the upper 25% of scores).

* The Interquartile Range (or IQR): 

This is the box plot showing the middle 50% of scores (i.e., the range between the 25th and 75th percentile).


Transcript lncov1
```{r}
names_facet <- c(Con = "Control", RNAi = "RNAi")

plot1 <- plot_bootstrap(so, "lncov1", units = "est_counts", color_by = "condition") +

ggtitle("lncov1") + theme_bw() + 
  theme(legend.position="none", plot.title = element_text(size = 14, face="italic")) +
  ylab(expression("Estimated counts - log"[2])) + xlab("Samples") + 
  facet_rep_wrap(~condition, labeller = as_labeller(names_facet), scales='free_x', repeat.tick.labels = "All", strip.position="bottom") + scale_fill_manual(values=c( "#fd8183", "#74C476"))

plot1
ggsave(file="results/boxplot1_lncov1.jpeg", height=5, width=9, dpi=300)
```


# kruppel NM_001242470.1
```{r}
plot1.1 <- plot_bootstrap(so, "NM_001242470.1", units = "est_counts", color_by = "condition") +

ggtitle("kruppel") + theme_bw() + 
  theme(legend.position="none", plot.title = element_text(size = 14, face="italic")) +
  ylab(expression("Estimated counts - log"[2])) + xlab("Samples") + 
  facet_rep_wrap(~condition, labeller = as_labeller(names_facet), scales='free_x', repeat.tick.labels = "All", strip.position="bottom") + scale_fill_manual(values=c( "#fd8183", "#74C476"))

plot1.1
ggsave(file="results/boxplot1_kruppel.jpeg", height=5, width=9, dpi=300)
```




Transcript XM_001120691.5 = Loc726407
```{r}
plot2 <- plot_bootstrap(so, "XM_001120691.5", units = "est_counts", color_by = "condition") +

ggtitle("LOC726407") + theme_bw() + theme(legend.position="none", plot.title = element_text(size = 14, face="italic")) +
  ylab(expression("Estimated counts - log"[2])) + xlab("Samples") + 
  facet_rep_wrap(~condition, labeller = as_labeller(names_facet), scales='free_x', repeat.tick.labels = "All", strip.position="bottom") + 
  scale_fill_manual(values=c( "#fd8183", "#74C476"))

plot2
ggsave(file="results/boxplot2_Loc726407.jpeg", height=5, width=9, dpi=300)
```


Transcript XM_393605.7 = Gapdh
```{r}
plot3 <- plot_bootstrap(so, "XM_393605.7", units = "est_counts", color_by = "condition") +

ggtitle("Gapdh") + theme_bw() + theme(legend.position="none", plot.title = element_text(size = 14, face="italic")) +
  ylab(expression("Estimated counts - log"[2])) + xlab("Samples") + 
  facet_rep_wrap(~condition, labeller = as_labeller(names_facet), scales='free_x', repeat.tick.labels = "All", strip.position="bottom") + 
  scale_fill_manual(values=c("#fd8183", "#74C476"))

plot3
ggsave(file="results/boxplot3_Gapdh.jpeg", height=5, width=9, dpi=300)
```


XM_624635.6 para Tudor-SN
```{r}
plot4 <- plot_bootstrap(so, "XM_624635.6", units = "est_counts", color_by = "condition") + 

ggtitle("Tudor-SN") + theme_bw() + 
  ylab(expression("Estimated counts - log"[2])) + xlab("Samples") + 
  facet_rep_wrap(~condition, labeller = as_labeller(names_facet), scales='free_x', repeat.tick.labels = "All", strip.position="bottom") + 
  scale_fill_manual(values=c("#fd8183", "#74C476"))

plot4
ggsave(file="results/boxplot4_Tudor-SN.jpeg", height=5, width=9, dpi=300)
```


XM_006569892.2 = ef1alfa
```{r}
plot5 <- plot_bootstrap(so, "XM_006569892.2", units = "est_counts", color_by = "condition") +

ggtitle("Ef1α") + theme_bw(11) + 
  theme(legend.position="none", plot.title = element_text(size = 16, face="italic"))+
        #axis.text.x = element_text(angle = 45,  hjust=1))
  ylab(expression("Estimated counts - log"[2])) + xlab("Samples") + 
  facet_rep_wrap(~condition, labeller = as_labeller(names_facet), scales='free_x', 
                 repeat.tick.labels = "All", strip.position="bottom", ncol = 5) + 
  scale_fill_manual(values=c("#fd8183", "#74C476"))


plot5
ggsave(file="results/boxplot5_ef1alfa_v03.jpeg", height=8, width=11, dpi=300)
```


rp49 = XM_006564315.3
```{r}
plot6 <- plot_bootstrap(so, "XM_006564315.3", units = "est_counts", color_by = "condition") +

ggtitle("rp49") + theme_bw(11) + 
  theme(legend.position="none", plot.title = element_text(size = 16, face="italic"))+
  ylab(expression("Estimated counts - log"[2])) + xlab("Samples") + 
  facet_rep_wrap(~condition, labeller = as_labeller(names_facet), scales='free_x', 
                 repeat.tick.labels = "All", strip.position="bottom", ncol = 5) + 
  scale_fill_manual(values=c("#fd8183", "#74C476"))


plot6
ggsave(file="results/boxplot4_Tudor-SN.jpeg", height=8, width=11, dpi=300)
```


Distribuition of est_counts of transcripts:
```{r, fig.height=16, fig.width=10}
plot_grid(plot1 + theme(legend.position="right"),  
          plot2 + theme(legend.position="right"), 
          #plot3 + theme(legend.position="right"),
          plot5 + theme(legend.position="right"),
          plot4 + theme(legend.position="right"),
          #plot4 + theme(legend.position="none") + ylab(NULL),
          labels = c("A", "B", "C", "D"),
          ncol = 1, nrow = 4)
ggsave(file="results/boxplot5_all.jpeg", height=16, width=10, dpi=300)
```

## 6. Heatmaps

we can perform an expression heatmap for select transcripts, transcripts of interest:
```{r, fig.height=5, fig.width=9}
# Filtando a matriz pelos transcritos de interesse
mat <- sleuth_results_RNAi[sleuth_results_RNAi$target_id %in% txI, ]
  
plot_transcript_heatmap(DE_RNAi, units = "est_counts", transcripts = mat$target_id)
```

## Referências

https://pachterlab.github.io/sleuth/walkthroughs  
https://pachterlab.github.io/sleuth_walkthroughs/trapnell/analysis.html  
https://www.nature.com/articles/nmeth.4324.pdf?origin=ppub  
https://liorpachter.wordpress.com/2015/08/17/a-sleuth-for-rna-seq/  
https://hbctraining.github.io/DGE_workshop_salmon/lessons/09_sleuth.html#:~:text=What%20is%20Sleuth%3F,expression%20analysis%20of%20gene%20isoforms.  
https://rdrr.io/github/pachterlab/sleuth/src/R/plots.R  
https://www.simplypsychology.org/boxplots.html  
